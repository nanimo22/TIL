{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yykim_LuhnSummarize Class.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMOzxuE1kikFgKF0BGe2Sx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanimo22/TIL/blob/master/yykim/yykim_LuhnSummarize_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyafDjPjz_Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k98MLDRCEil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "ed1dd801-9d86-40b5-d0dc-d78f858b26ec"
      },
      "source": [
        "#konlpy 설치\n",
        "!pip install konlpy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 2.7MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/49/725710351d78d26c65337b1e3b322d7b27b34b704535ab56afc0d9ab0ffd/JPype1-1.0.1-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 33.5MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, JPype1, tweepy, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.0.1 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNl-pJKITXP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvFjJxqUTgAF",
        "colab_type": "text"
      },
      "source": [
        "## Luhn Summarize Class로 만들기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVOk6wYCTmVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuhnSummarize:\n",
        "    def __init__(self, text, doc, keysentence_number=1, min=0.01, max=0.2):\n",
        "    # text는 문서 전체, doc는 문서 내 문장을 각각 리스트화 한 이중 리스트\n",
        "        self.keysentence_number = keysentence_number\n",
        "        self.doc = doc\n",
        "        self.min = min\n",
        "        self.max = max\n",
        "        self.sentence_score = []\n",
        "\n",
        "\n",
        "    def _make_score(self):\n",
        "        from konlpy.tag import Kkma\n",
        "        kkma= Kkma()\n",
        "\n",
        "        #전체 문서 토크나이징\n",
        "        total_token = kkma.morphs(text)\n",
        "        unique_token = np.unique(total_token)\n",
        "        \n",
        "        #{유니크 토큰: 토큰 등장 횟수}로 딕셔너리 정리        \n",
        "        n_unique_token=[]\n",
        "        for token in unique_token:\n",
        "            tmp = total_token.count(token)\n",
        "            n_unique_token.append(tmp)\n",
        "        dict_unique_token = dict(zip(list(unique_token),n_unique_token))\n",
        "\n",
        "        #문장별로 토크나이즈\n",
        "        tokenized_sens = []\n",
        "        for sens in doc:\n",
        "            tokenized_sen = kkma.morphs(sens)\n",
        "            tokenized_sens.append(tokenized_sen)\n",
        "\n",
        "        # 각 문장의 토큰들을 해당 토큰의 빈도수/전체토큰수(score)로 치환\n",
        "        import copy\n",
        "        words_score = tokenized_sens.copy()\n",
        "\n",
        "        for sen_idx, sen in enumerate(tokenized_sens):\n",
        "            for morph_idx,morph in enumerate(sen):\n",
        "                words_score[sen_idx][morph_idx] = dict_unique_token[morph]/len(total_token)\n",
        "\n",
        "        # 중요 단어로 판단된 단어들의 문장 내 인덱스 확인\n",
        "        keywords_idx=[]\n",
        "        for sen_idx, sen in enumerate(words_score):\n",
        "            keywords_idx_tmp = []\n",
        "            for morph_idx,morph in enumerate(sen):\n",
        "                if self.min < morph < self.max:\n",
        "                    keywords_idx_tmp.append(morph_idx)\n",
        "            keywords_idx.append(keywords_idx_tmp)\n",
        "\n",
        "        for sens in keywords_idx:\n",
        "            try:\n",
        "                self.sentence_score.append(np.square(sens[-1]-sens[0]+1)/len(sens))\n",
        "            except:\n",
        "                self.sentence_score.append(0) #문장 내에 중요 단어가 1개 이하인 경우\n",
        "        return self.sentence_score                       \n",
        "    \n",
        "    def luhn_summarize(self):\n",
        "        self._make_score()\n",
        "        sort = np.argsort(self.sentence_score)[::-1]\n",
        "        top = sort[0:self.keysentence_number]\n",
        "\n",
        "        keysentence_ls = []\n",
        "        for i in top :\n",
        "            keysentence_ls.append(self.doc[i])\n",
        "        return keysentence_ls        "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjGCod6R5Unk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=\"\"\"\n",
        "코로나19 대응 의료 인공지능 컨소시엄 출범 산학연병 인공지능 전문가 20여 명으로 구성, 기술‧응용 공동 연구\n",
        "지난 8일, 창립준비 모임…미영상의학회 COVID-19 컨소시엄과도 협력\n",
        "\n",
        "코로나19 바이러스의 세계적 감염 유행에 효과적으로 대응하기 위해 관련 전문가들이 모인 ‘코로나19 감염 대응을 위한 의료 인공지능 컨소시엄’이 9월 1일에 출범한다. \n",
        "\n",
        "연세대 의대, 한국전자통신원, 네이버 등 산학연병 20여 명이 참여하는 컨소시엄에서는 인공지능 기술과 응용 분야를 공동으로 연구하고 개발, 검증할 예정이다. 또 이 인공지능 기술을 적용하기 위해 필요한 데이터를 수집, 공유, 활용한다. 나아가 다양한 산학연병 전문가들이 국내외적으로 협력하고 공동으로 대응해 나갈 예정이다.\n",
        " \n",
        "컨소시엄에는 15개 기관의 20여 명 전문가들이 참여했다. 연세대 의과대학에서는 박유랑(의생명시스템정보학), 김휘영(방사선의과학연구소), 심규원(신경외과), 염준섭(감염내과), 최병욱(영상의학과, 사진), 허진(영상의학과) 교수가 참여했다.\n",
        "\n",
        "대학군에서는 권인호(동아대), 김남국(울산대), 김윤현(전남대), 김진영(계명대), 박상준(서울대), 신수용(성균관대), 정명진(성균관대), 진광남(서울대), 홍헬렌(서울여대) 교수가 , 산업군에서는 김기환(루닛), 이동훈(카카오), 정규환(뷰노), 최우식(딥노이드), 최정필(코어라인소프트), 하정우(네이버)가 기업을 대표해 동참했다.\n",
        "\n",
        "이 밖에도 전종홍(한국전자통신연구원), 김경훈(정보통신정책연구원), 예종철(한국과학기술원) 교수도 포함됐다.\n",
        " \n",
        "인공지능 컨소시엄은 지난 7월 8일에 창립 준비 위원 모임을 했고, 연세대 의대 영상의학과 최병욱 교수(사진)가 준비위원장으로 선출됐다.\n",
        "\n",
        "컨소시엄은 북미영상의학회에서 시작한 COVID-19 RICORD 컨소시엄, 유럽연합에서 시작한 COVID-19 이미징 AI 이니셔티브 등과 함께 국제 협력 활동을 펼칠 계획이며, 코로나19 대응을 위한 AI 핵심표준 개발도 목표로 하고 있다. 아울러 대한의료인공지능학회, 대한영상의학회 등 국내 관련 학회와도 적극 협력할 계획이다.\n",
        " \n",
        "한편 오는 7월 24일(금)에는 온라인 워크숍을 개최해 코로나 19 감염대응 의료 인공지능 관련 동향발표 및 연구개발 사례 소개가 있을 예정이다.\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGT5Pbjc5c4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#문서 문장으로 쪼개기 (해당 문서에서는 줄공백으로 구분)\n",
        "doc = text.split('\\n')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa-ACJBc5rie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "649c2aed-cdb8-4c22-8a26-89b745f38a4b"
      },
      "source": [
        "for sentence in doc:\n",
        "    if sentence == '' or sentence == ' ':\n",
        "        doc.remove(sentence)\n",
        "print(doc)\n",
        "\n",
        "print(len(doc))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['코로나19 대응 의료 인공지능 컨소시엄 출범 산학연병 인공지능 전문가 20여 명으로 구성, 기술‧응용 공동 연구', '지난 8일, 창립준비 모임…미영상의학회 COVID-19 컨소시엄과도 협력', '코로나19 바이러스의 세계적 감염 유행에 효과적으로 대응하기 위해 관련 전문가들이 모인 ‘코로나19 감염 대응을 위한 의료 인공지능 컨소시엄’이 9월 1일에 출범한다. ', '연세대 의대, 한국전자통신원, 네이버 등 산학연병 20여 명이 참여하는 컨소시엄에서는 인공지능 기술과 응용 분야를 공동으로 연구하고 개발, 검증할 예정이다. 또 이 인공지능 기술을 적용하기 위해 필요한 데이터를 수집, 공유, 활용한다. 나아가 다양한 산학연병 전문가들이 국내외적으로 협력하고 공동으로 대응해 나갈 예정이다.', '컨소시엄에는 15개 기관의 20여 명 전문가들이 참여했다. 연세대 의과대학에서는 박유랑(의생명시스템정보학), 김휘영(방사선의과학연구소), 심규원(신경외과), 염준섭(감염내과), 최병욱(영상의학과, 사진), 허진(영상의학과) 교수가 참여했다.', '대학군에서는 권인호(동아대), 김남국(울산대), 김윤현(전남대), 김진영(계명대), 박상준(서울대), 신수용(성균관대), 정명진(성균관대), 진광남(서울대), 홍헬렌(서울여대) 교수가 , 산업군에서는 김기환(루닛), 이동훈(카카오), 정규환(뷰노), 최우식(딥노이드), 최정필(코어라인소프트), 하정우(네이버)가 기업을 대표해 동참했다.', '이 밖에도 전종홍(한국전자통신연구원), 김경훈(정보통신정책연구원), 예종철(한국과학기술원) 교수도 포함됐다.', '인공지능 컨소시엄은 지난 7월 8일에 창립 준비 위원 모임을 했고, 연세대 의대 영상의학과 최병욱 교수(사진)가 준비위원장으로 선출됐다.', '컨소시엄은 북미영상의학회에서 시작한 COVID-19 RICORD 컨소시엄, 유럽연합에서 시작한 COVID-19 이미징 AI 이니셔티브 등과 함께 국제 협력 활동을 펼칠 계획이며, 코로나19 대응을 위한 AI 핵심표준 개발도 목표로 하고 있다. 아울러 대한의료인공지능학회, 대한영상의학회 등 국내 관련 학회와도 적극 협력할 계획이다.', '한편 오는 7월 24일(금)에는 온라인 워크숍을 개최해 코로나 19 감염대응 의료 인공지능 관련 동향발표 및 연구개발 사례 소개가 있을 예정이다.']\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdsr2_bX6Cgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "luhn_summarize = LuhnSummarize(text, doc, keysentence_number=3) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS5nM10Y6ZPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "bf11b1c4-5d3d-4fdf-c81e-dce5bb2a1a18"
      },
      "source": [
        "luhn_summarize.luhn_summarize() #괄호의 단어점수 때문에 첫번째 문장이 잘못 선정됨(전처리 필요..)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['대학군에서는 권인호(동아대), 김남국(울산대), 김윤현(전남대), 김진영(계명대), 박상준(서울대), 신수용(성균관대), 정명진(성균관대), 진광남(서울대), 홍헬렌(서울여대) 교수가 , 산업군에서는 김기환(루닛), 이동훈(카카오), 정규환(뷰노), 최우식(딥노이드), 최정필(코어라인소프트), 하정우(네이버)가 기업을 대표해 동참했다.',\n",
              " '컨소시엄은 북미영상의학회에서 시작한 COVID-19 RICORD 컨소시엄, 유럽연합에서 시작한 COVID-19 이미징 AI 이니셔티브 등과 함께 국제 협력 활동을 펼칠 계획이며, 코로나19 대응을 위한 AI 핵심표준 개발도 목표로 하고 있다. 아울러 대한의료인공지능학회, 대한영상의학회 등 국내 관련 학회와도 적극 협력할 계획이다.',\n",
              " '연세대 의대, 한국전자통신원, 네이버 등 산학연병 20여 명이 참여하는 컨소시엄에서는 인공지능 기술과 응용 분야를 공동으로 연구하고 개발, 검증할 예정이다. 또 이 인공지능 기술을 적용하기 위해 필요한 데이터를 수집, 공유, 활용한다. 나아가 다양한 산학연병 전문가들이 국내외적으로 협력하고 공동으로 대응해 나갈 예정이다.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVF7qTo26g92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}